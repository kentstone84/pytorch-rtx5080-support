version: '3.8'

services:
  # RTX-STone development environment
  rtx-stone-dev:
    build:
      context: .
      dockerfile: Dockerfile
    image: rtx-stone:latest
    container_name: rtx-stone-dev
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./:/workspace
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "8888:8888"  # Jupyter
      - "8000:8000"  # vLLM API
      - "6006:6006"  # TensorBoard
    stdin_open: true
    tty: true
    command: /bin/bash

  # RTX-STone Jupyter server
  rtx-stone-jupyter:
    build:
      context: .
      dockerfile: Dockerfile
    image: rtx-stone:latest
    container_name: rtx-stone-jupyter
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./notebooks:/workspace/notebooks
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "8888:8888"
    command: jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root --no-browser

  # RTX-STone vLLM server
  rtx-stone-vllm:
    build:
      context: .
      dockerfile: Dockerfile
    image: rtx-stone:latest
    container_name: rtx-stone-vllm
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MODEL_NAME=meta-llama/Llama-3.2-3B
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "8000:8000"
    command: >
      bash -c "vllm serve ${MODEL_NAME:-meta-llama/Llama-3.2-3B}
      --host 0.0.0.0
      --port 8000
      --gpu-memory-utilization 0.9"

  # RTX-STone benchmarking
  rtx-stone-benchmark:
    build:
      context: .
      dockerfile: Dockerfile
    image: rtx-stone:latest
    container_name: rtx-stone-benchmark
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./:/workspace
      - ./benchmark_results:/workspace/results
    command: >
      bash -c "python benchmark.py &&
      python benchmark_triton.py &&
      python compare_performance.py --save-results"

networks:
  default:
    name: rtx-stone-network
